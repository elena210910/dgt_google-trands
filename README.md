# Descripci√≥n del proyecto
## An√°lisis de las matriculaciones de veh√≠culos y su correlaci√≥n con Google Trends
Este proyecto tiene como objetivo analizar los datos de las matriculaciones diarias de veh√≠culos 
([Microdatos de Matriculaciones de Veh√≠culos (diarios)de DGT](https://www.dgt.es/menusecundario/dgt-en-cifras/dgt-en-cifras-resultados/dgt-en-cifras-detalle/Microdatos-de-Matriculaciones-de-Vehiculos-diarios/), que incluyen informaci√≥n sobre los veh√≠culos que se incorporan al Registro de Veh√≠culos junto con sus caracter√≠sticas t√©cnicas. Parece razonable asumir que estos datos reflejan veh√≠culos nuevos, ya que se basan en las primeras matriculaciones que se realizan en el Registro de Veh√≠culos. Sin embargo, ser√≠a ideal confirmarlo revisando la fuente oficial o la documentaci√≥n de donde provienen estos datos. En este caso, utilizo los datos disponibles como referencia para el an√°lisis.üöóüöô
El prop√≥sito principal es evaluar si existe una correlaci√≥n entre las matriculaciones de veh√≠culos (ventas de autom√≥viles) y los datos de inter√©s de b√∫squeda en üîç **Google Trends.**

## Sobre los datos obtenidos
Nos proporcionan archivos en formato .txt correspondientes a los d√≠as desde el **2 de diciembre hasta el 26 de diciembre**, incluyendo todos los d√≠as excepto los fines de semana. Esto es l√≥gico, ya que la DGT no opera durante los fines de semana.

Un ejemplo de la estructura del archivo.

![](https://github.com/user-attachments/assets/f7bb77cf-70b9-450e-9c54-514f435b98b2)


Al iniciar el an√°lisis de los archivos con Python, me encontr√© con varias dificultades que tuve que resolver paso a paso:

**Columnas de diferentes tama√±os y formatos:**
Los archivos .txt no ten√≠an encabezados y la distribuci√≥n de las columnas variaba significativamente entre algunos d√≠as.
Fue necesario calcular manualmente la anchura de las columnas para estructurar correctamente los datos.

**Formato de fechas:**
Las fechas estaban en un formato que dificultaba su procesamiento. Fue necesario normalizarlas para que fueran reconocidas correctamente por Python como objetos de tipo datetime.
üìö
**Duplicados y limpieza de datos:**
Identifiqu√© muchas filas duplicadas, y tuve que decidir si mantenerlas como representaciones v√°lidas de ventas m√∫ltiples o eliminarlas para un an√°lisis m√°s limpio.

**Prefijos y datos adicionales en columnas:**
En algunas columnas, como la de localidades, nombre de marca u modelo, hab√≠a prefijos alfanum√©ricos que necesitaban ser eliminados para obtener el nombre correcto.

***Para este proyecto, se han utilizado las siguientes bibliotecas de Python:***üòäüìö‚ú®

‚úîÔ∏è**pandas**
   
Para leer, procesar y analizar datos de archivos Excel y archivos de texto.
Funciones principales: read_excel, concat, groupby, value_counts, to_excel.

‚úîÔ∏è**os**
   
Para trabajar con el sistema de archivos, buscar y procesar archivos en una carpeta.

‚úîÔ∏è**re**

Para procesar cadenas y eliminar prefijos o caracteres innecesarios utilizando expresiones regulares.

‚úîÔ∏è**pytrends**

Para interactuar con la API de Google Trends y obtener datos sobre el inter√©s de b√∫squeda.

‚úîÔ∏è**plotly** (si fue utilizada para gr√°ficos)üìà
   
Para crear visualizaciones de datos interactivas.

‚úîÔ∏è**openpyxl**
   
Para leer y escribir datos en formato Excel.



